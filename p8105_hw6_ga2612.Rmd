---
title: "p8105_hw6_ga2612"
author: "Lupe Antonio"
date: "12/1/2023"
output:
  github_document:
    toc: TRUE
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
library(broom)
library(purrr)
library(modelr)
```

## Problem 1

```{r, message = FALSE}
#loading data
homicide_data <- read_csv('data_hw6/homicide_data.csv') %>%
  mutate(
    city_state = str_c(city, state, sep = ', '),
    #unsolved == 0, solved == 1
    resolution = case_when(
      disposition == 'Closed without arrest' ~ 0,
      disposition == 'Open/No arrest' ~ 0,
      disposition == 'Closed by arrest' ~ 1),
    #making victime_age numeric
    victim_age = as.numeric(victim_age)) %>%
  #excluding cities
  filter(city_state != 'Dallas, TX',
         city_state != 'Phoenix, AZ',
         city_state != 'Kansas City, MO',
         city_state != 'Tulsa, AL',
        #filtering victim_race
        victim_race == 'White' | victim_race == 'Black')
```


```{r, message = FALSE}
baltimore_data <- homicide_data %>%
  filter(city_state == 'Baltimore, MD')

#fitting glm model
baltimore_logistic <- baltimore_data %>%
  glm(resolution ~ victim_age + victim_sex + victim_race,
    data = ., family = binomial())


#obtaining estimate
baltimore_logistic %>%
  tidy() %>%
  filter(term == 'victim_sexMale') %>%
  mutate(adj_OR = exp(estimate),
         OR_low = exp(estimate - 1.96 * std.error),
         OR_upper = exp(estimate + 1.96 * std.error)) %>%
  select(term, adj_OR, OR_low, OR_upper)

#obtaining confidence interval for checking purposes
exp(confint(baltimore_logistic)['victim_sexMale', ])
```


```{r}
cities_data <- homicide_data %>%
  nest(data = -city_state) %>%
  mutate(
    models = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race,
                                 data = df, family = binomial())),
    tidy_models = map(models, tidy)) %>%
  select(-models, data) %>%
  unnest(cols = tidy_models) %>%
  filter(term == 'victim_sexMale') %>%
  mutate(adj_OR = exp(estimate),
         OR_low = exp(estimate - 1.96*std.error),
         OR_upper = exp(estimate + 1.96*std.error)) %>%
  select(city_state, term, adj_OR, OR_low, OR_upper)

cities_data %>%
  knitr::kable()
```


```{r}
cities_data %>%
  mutate(city_state = fct_reorder(city_state, adj_OR)) %>%
  ggplot(aes(x = city_state, y = adj_OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

From the table above, we can see that the majority of cities have adjusted odds ratio less than 1. This suggest that among crimes against Males they have lower odds of resolution compared to crimes against Females, after controlling for the victims age and race. 



## Problem 2

```{r}
#loading data
weather_df <- 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

The boostrap is helpful when you’d like to perform inference for a parameter / value / summary that doesn’t have an easy-to-write-down distribution in the usual repeated sampling framework. We’ll focus on a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data:

r̂ 2
log(β̂ 1∗β̂ 2)
Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2
 and log(β̂ 0∗β̂ 1)
. Note: broom::glance() is helpful for extracting r̂ 2
 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing log(β̂ 1∗β̂ 2)


```{r}
#fitting SLR model
model_p2 <- lm(tmax ~ tmin + prcp, data = weather_df)


```



## Problem 3

```{r}
birthweight <- read_csv('data_hw6/birthweight.csv') %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))
```

Describe your modeling process 

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate.

Note that although we expect your model to be reasonable, model building itself is not a main idea of the course and we don’t necessarily expect your model to be “optimal”.


```{r}
#no missing data
birthweight[!complete.cases(birthweight), ]
```

```{r}
#regression model
model_p3 <- lm(bwt ~ babysex + blength + fincome + smoken,
               data = birthweight)


#plot for model
birthweight %>%
  add_residuals(model_p3) %>%
  add_predictions(model_p3) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, color = 'red')
```

```{r}
#model 2
model2_p3 <- lm(bwt ~ blength + gaweeks,
                data = birthweight)

#model 3
model3_p3 <- lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex +
                  bhead*blength*babysex,
                data = birthweight)
```

```{r}

```

